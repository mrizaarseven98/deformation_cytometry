{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2d9cc-2e5e-47e4-bfd8-c6a8128d07ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "\n",
    "import Analysis_utils as au"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e527a0a3-89cf-4b7e-b866-eee1b81841eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the working directory and paths\n",
    "working_dir = Path(os.getcwd())\n",
    "segmentation_dir = os.path.join(working_dir, 'segmentation_outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cbd054-e1c5-4f72-b81a-f82dd152fc72",
   "metadata": {},
   "source": [
    "Attention: if not performed segmentation on this folder you will not have the folder named 'segmentation_outputs', if you don't want to perform the segmentation for computational time reasons or others you can dowload the folder from the [Google drive](https://drive.google.com/drive/folders/15EFxsOXxLsh5dPxTruXf7JRL8ahgMC0D?usp=drive_link). Place the folder togheter with the 'Part C.ipynb' notebook and the 'Analysis_utils.py' file and run all the cells in the order. Once you have the csv data you can skip the code for creating them (also these are present on the drive and can be downloaded)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a567b961-2044-47b0-bf52-2e6547e6c93b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Extract features from the segmentations outputs and create csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6524f5a4-0a74-4e11-b2df-50dc87a89c6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate over each folder in the segmentation_outputs directory\n",
    "for folder in os.listdir(segmentation_dir):\n",
    "    folder_path = os.path.join(segmentation_dir, folder)\n",
    "    txt_dir = os.path.join(folder_path, 'txt_outlines')\n",
    "    img_dir = os.path.join(folder_path, 'outlines')\n",
    "    csv_path = os.path.join(segmentation_dir, f\"{folder}_data.csv\")\n",
    "    filtered_contour_csv_path = os.path.join(segmentation_dir, f\"{folder}_data_filtered_contour.csv\")\n",
    "\n",
    "    data_list = []\n",
    "    filtered_data_list = []\n",
    "\n",
    "    if os.path.isdir(txt_dir):\n",
    "        # Process each .txt file in the txt_outlines directory\n",
    "        for txt_file in sorted(os.listdir(txt_dir)):\n",
    "            if txt_file.endswith('.txt'):\n",
    "                txt_file_path = os.path.join(txt_dir, txt_file)\n",
    "                frame_number = int(txt_file.split('_')[1])  # Corrected frame number extraction\n",
    "                \n",
    "                # Load the corresponding image for the current contour file\n",
    "                img_file = f\"frame_{frame_number:04d}_outlines.png\"\n",
    "                img_file_path = os.path.join(img_dir, img_file)\n",
    "                image = cv2.imread(img_file_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                if image is None:\n",
    "                    print(f\"Failed to load image: {img_file_path}\")\n",
    "                    continue\n",
    "\n",
    "                contours = au.get_contours_from_file(txt_file_path)\n",
    "\n",
    "                # Process each contour and calculate features\n",
    "                for contour in contours:\n",
    "\n",
    "                    area, perimeter, circularity, deformation, solidity, mean_intensity = au.calculate_features(image, contour)\n",
    "\n",
    "                    data_list.append({\n",
    "                        'Frame': frame_number,\n",
    "                        'Area': area,\n",
    "                        'Perimeter': perimeter,\n",
    "                        'Circularity': circularity,\n",
    "                        'Deformation': deformation,\n",
    "                        'Solidity': solidity,\n",
    "                        'MeanIntensity': mean_intensity\n",
    "                    })\n",
    "                    \n",
    "                    # Check if the contour is touching the edge of the image\n",
    "                    if not au.is_contour_touching_edge(contour, image.shape[:2]):\n",
    "                        filtered_data_list.append({\n",
    "                            'Frame': frame_number,\n",
    "                            'Area': area,\n",
    "                            'Perimeter': perimeter,\n",
    "                            'Circularity': circularity,\n",
    "                            'Deformation': deformation,\n",
    "                            'Solidity': solidity,\n",
    "                            'MeanIntensity': mean_intensity\n",
    "                        })\n",
    "\n",
    "        # Write all data to cvs\n",
    "        with open(csv_path, 'w', newline='') as csv_file:\n",
    "            fieldnames = ['Frame', 'Area', 'Perimeter', 'Circularity', 'Deformation', 'Solidity', 'MeanIntensity']\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(data_list)\n",
    "        print(f\"Data from {folder} has been saved to {segmentation_dir}\")\n",
    "        \n",
    "        df = pd.read_csv(csv_path)\n",
    "        # Get the number of rows and columns\n",
    "        num_rows, num_columns = df.shape\n",
    "        print(f\"The CSV file '{csv_path}' contains {num_rows} rows and {num_columns} columns.\")\n",
    "\n",
    "        with open(filtered_contour_csv_path, 'w', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(filtered_data_list)\n",
    "        print(f\"Filtered data from {folder} has been saved to {segmentation_dir}\")\n",
    "        \n",
    "        df = pd.read_csv(filtered_contour_csv_path)\n",
    "        # Get the number of rows and columns\n",
    "        num_rows, num_columns = df.shape\n",
    "        print(f\"The CSV file '{filtered_contour_csv_path}' contains {num_rows} rows and {num_columns} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd47888b-2196-454f-ac89-efea1286dc0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Plot all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceca6df-ec9d-4f3f-83ab-4598bba169c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_frames = []\n",
    "\n",
    "for file in os.listdir(segmentation_dir):\n",
    "    if file.endswith('_data.csv'):\n",
    "        df = pd.read_csv(os.path.join(segmentation_dir, file))\n",
    "        df['Dataset'] = file.replace('_data.csv', '')\n",
    "        data_frames.append(df)\n",
    "\n",
    "all_data = pd.concat(data_frames)\n",
    "\n",
    "# Variables to plot\n",
    "plot_variables = ['Area', 'Perimeter', 'Circularity', 'Deformation', 'Solidity', 'MeanIntensity']\n",
    "\n",
    "num_rows = len(plot_variables)\n",
    "# Plotting distributions for each variable\n",
    "plt.figure(figsize=(18, num_rows * 4))\n",
    "for i, variable in enumerate(plot_variables):\n",
    "    au.plot_distribution(all_data, variable, i+1, num_rows, 2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting box plots with scatter overlay for each variable\n",
    "plt.figure(figsize=(18, num_rows * 4))  # Adjust the figure size based on the number of variables\n",
    "for i, variable in enumerate(plot_variables):\n",
    "    au.plot_boxplot_with_scatter(all_data, variable, i+1, num_rows)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee2950c-c614-40ec-8e5a-e40b1cb0913b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Plot all data with filtered contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14a7f68-2bf6-4d0d-b60d-dbdcce842d44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_frames = []\n",
    "\n",
    "for file in os.listdir(segmentation_dir):\n",
    "    if file.endswith('_data_filtered_contour.csv'):\n",
    "        df = pd.read_csv(os.path.join(segmentation_dir, file))\n",
    "        df['Dataset'] = file.replace('_data_filtered_contour.csv', '')\n",
    "        data_frames.append(df)\n",
    "\n",
    "all_data = pd.concat(data_frames)\n",
    "\n",
    "# Variables to plot\n",
    "plot_variables = ['Area', 'Perimeter', 'Circularity', 'Deformation', 'Solidity', 'MeanIntensity']\n",
    "\n",
    "num_rows = len(plot_variables)\n",
    "# Plotting distributions for each variable\n",
    "plt.figure(figsize=(18, num_rows * 4))\n",
    "for i, variable in enumerate(plot_variables):\n",
    "    au.plot_distribution(all_data, variable, i+1, num_rows, 2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting box plots with scatter overlay for each variable\n",
    "plt.figure(figsize=(18, num_rows * 4))  # Adjust the figure size based on the number of variables\n",
    "for i, variable in enumerate(plot_variables):\n",
    "    au.plot_boxplot_with_scatter(all_data, variable, i+1, num_rows)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de80f6c5-1b32-4e06-9d5b-2f940a24dbcf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Create new csv without wrong contours and without outliers data in 'Solidity' and 'MeanIntensity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb191aa-5f79-4ed2-8820-564719f51eee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = ['CellA_GFP', 'CellA_ShME480', 'CellB_GFP', 'CellB_ME480']\n",
    "\n",
    "# Features to analyze\n",
    "selected_features = ['Solidity', 'MeanIntensity']\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    dataset_data = pd.read_csv(os.path.join(segmentation_dir, f'{dataset_name}_data_filtered_contour.csv'))\n",
    "    # Remove outliers for selected features\n",
    "    filtered_data = au.remove_selected_outliers(dataset_data, selected_features)\n",
    "    filtered_data_csv_path = os.path.join(segmentation_dir, f'{dataset_name}_data_filtered_contour_and_outliers.csv')    \n",
    "    # Save the filtered data to a CSV file\n",
    "    filtered_data.to_csv(filtered_data_csv_path, index=False)\n",
    "    print(f\"Outlier filtered data from {dataset_name} has been saved to {segmentation_dir}\")\n",
    "    \n",
    "\n",
    "    \n",
    "    df = pd.read_csv(filtered_data_csv_path)\n",
    "    num_rows, num_columns = df.shape\n",
    "    print(f\"The CSV file '{filtered_data_csv_path}' contains {num_rows} rows and {num_columns} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e54df8-dcbc-4761-97b3-4812390e2dea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Plot filtered data per cell type A/B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df52372-278f-4434-bdba-2bb6a160b286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_frames = []\n",
    "\n",
    "cella_gfp_data = pd.read_csv('segmentation_outputs/CellA_GFP_data_filtered_contour_and_outliers.csv')\n",
    "cella_shme480_data = pd.read_csv('segmentation_outputs/CellA_ShME480_data_filtered_contour_and_outliers.csv')\n",
    "cellb_gfp_data = pd.read_csv('segmentation_outputs/CellB_GFP_data_filtered_contour_and_outliers.csv')\n",
    "cellb_me480_data = pd.read_csv('segmentation_outputs/CellB_ME480_data_filtered_contour_and_outliers.csv')\n",
    "\n",
    "cella_gfp_data['Dataset'] = 'CellA_GFP'\n",
    "cella_shme480_data['Dataset'] = 'CellA_ShME480'\n",
    "cellb_gfp_data['Dataset'] = 'CellB_GFP'\n",
    "cellb_me480_data['Dataset'] = 'CellB_ME480'\n",
    "\n",
    "# Combine data by cell type\n",
    "cella_data = pd.concat([cella_gfp_data, cella_shme480_data])\n",
    "cellb_data = pd.concat([cellb_gfp_data, cellb_me480_data])\n",
    "\n",
    "# Variables to plot\n",
    "plot_variables = ['Area', 'Perimeter', 'Circularity', 'Deformation', 'Solidity', 'MeanIntensity']\n",
    "\n",
    "# Plot distributions for Cell A and Cell B side by side\n",
    "num_rows = len(plot_variables)\n",
    "plt.figure(figsize=(18, num_rows * 4))\n",
    "for i, variable in enumerate(plot_variables):\n",
    "    au.plot_distribution_side_by_side(cella_data, cellb_data, variable, \n",
    "                                   f'Cell A - Distribution of {variable}', \n",
    "                                   f'Cell B - Distribution of {variable}', \n",
    "                                   num_rows, 2, 2 * i + 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot distributions for Cell A and Cell B side by side\n",
    "plt.figure(figsize=(18, num_rows * 4))\n",
    "for i, variable in enumerate(plot_variables):\n",
    "    au.plot_boxplots_side_by_side(cella_data, cellb_data, variable,\n",
    "                               f'Cell A - {variable} by Dataset',\n",
    "                               f'Cell B - {variable} by Dataset',\n",
    "                               num_rows, 2, 2 * i + 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aace13f-d6be-40fb-ba16-85c3ac210883",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Caculate statistics difference in 'Deformation' and check for statistical relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d25dc-f23f-4a9c-b12d-c6717793e7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate stats\n",
    "\n",
    "cella_gfp_stats = au.calculate_stats(cella_gfp_data, 'Deformation')\n",
    "cella_shme480_stats = au.calculate_stats(cella_shme480_data, 'Deformation')\n",
    "cellb_gfp_stats = au.calculate_stats(cellb_gfp_data, 'Deformation')\n",
    "cellb_me480_stats = au.calculate_stats(cellb_me480_data, 'Deformation')\n",
    "\n",
    "\n",
    "cella_mean_change = au.calculate_percentage_change(cella_gfp_stats[0], cella_shme480_stats[0])\n",
    "cella_median_change = au.calculate_percentage_change(cella_gfp_stats[1], cella_shme480_stats[1])\n",
    "cellb_mean_change = au.calculate_percentage_change(cellb_gfp_stats[0], cellb_me480_stats[0])\n",
    "cellb_median_change = au.calculate_percentage_change(cellb_gfp_stats[1], cellb_me480_stats[1])\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    'Dataset': ['CellA_GFP', 'CellA_ShME480', 'CellB_GFP', 'CellB_ME480'],\n",
    "    'Mean ± Std': [f\"{mean:.2f} ± {std:.2f}\" for mean, _, std in [cella_gfp_stats, cella_shme480_stats, cellb_gfp_stats, cellb_me480_stats]],\n",
    "    'Median': [median for _, median, _ in [cella_gfp_stats, cella_shme480_stats, cellb_gfp_stats, cellb_me480_stats]]\n",
    "})\n",
    "\n",
    "print(stats_df)\n",
    "\n",
    "au.print_change_description(\"Cell A\", cella_mean_change, \"mean\")\n",
    "au.print_change_description(\"Cell A\", cella_median_change, \"median\")\n",
    "au.print_change_description(\"Cell B\", cellb_mean_change, \"mean\")\n",
    "au.print_change_description(\"Cell B\", cellb_median_change, \"median\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b3e384-75ca-472c-ab1d-1d4d4c326599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# T-test for the datasets\n",
    "t_stat_a, p_value_a = ttest_ind(cella_gfp_data['Deformation'], cella_shme480_data['Deformation'], equal_var=False)\n",
    "t_stat_b, p_value_b = ttest_ind(cellb_gfp_data['Deformation'], cellb_me480_data['Deformation'], equal_var=False)\n",
    "\n",
    "print(f\"Cell A datasets t-test: t-statistic = {t_stat_a}, p-value = {p_value_a}\")\n",
    "print(f\"Cell B datasets t-test: t-statistic = {t_stat_b}, p-value = {p_value_b}\")\n",
    "\n",
    "print(f\"The difference in Deformation between datasets in Cell A is {au.interpret_p_value(p_value_a)}\")\n",
    "print(f\"The difference in Deformation between datasets in Cell B is {au.interpret_p_value(p_value_b)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a3dbd7-4dfe-4422-956d-ab279195ba78",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Visualize outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42350f3e-3e50-4681-a6a5-9c8a7e67d43c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = ['CellA_GFP', 'CellA_ShME480', 'CellB_GFP', 'CellB_ME480']\n",
    "features = ['Area', 'Perimeter', 'Circularity', 'Deformation', 'Solidity', 'MeanIntensity']\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    csv_path = os.path.join(segmentation_dir, f'{dataset_name}_data_filtered_contour_and_outliers.csv')\n",
    "    data_df = pd.read_csv(csv_path)\n",
    "\n",
    "    for feature in features:\n",
    "        au.plot_extreme_values_frames(data_df, feature, dataset_name, segmentation_dir, num_images=25)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d5d90-05d3-4683-88c6-777992ee50fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
